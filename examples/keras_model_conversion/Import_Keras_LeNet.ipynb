{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras LeNet Example\n",
    "\n",
    "This example trains a LeNet model in Keras, and then imports the resulting trained model into SAS Viya, using DLPy.  The test image data is scored by both models and the model results are compared. The results show that the imported and converted SAS Viya model duplicates the results produced by the original Keras model. This demonstrates the consistency between the open-source Keras model and the imported and converted SAS Viya model.  \n",
    "\n",
    "For best success before attempting this example in your own environment, consider reading Adrian Rosebrook's tutorial blog post on LeNet CNN models: https://www.pyimagesearch.com/2016/08/01/lenet-convolutional-neural-network-in-python. The blog provides a nice summary of LeNet, and this example follows the blog's LeNet model definition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important Note: Client and Server Definitions\n",
    "\n",
    "SAS Viya literature and technical documentation often refers to client and server entities.  In this scenario, the client is the computer that runs the Jupyter notebook with the example code.  The server is the computer that is running the Viya server.  These two computers might (or might not) use the same operating system, and might (or might not) have access to a common file system.  \n",
    "\n",
    "This example assumes that the client and server do not use the same operating system, but that they do have access to a common file system.  If the client and server in your environment do not have access to a common file system, you will need to copy or transfer files between client and server twice during this example.  The example in this notebook uses comments in cells to indicate when a given file should be moved from the client to the server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define variables to contain path specifications to  \n",
    "# the client and server machine image root directories\n",
    "client_image_root = \"<path/to/client/image/root>\"  # this is the CLIENT_IMAGE_ROOT directory\n",
    "server_image_root = \"<path/to/server/image/root>\"  # this is the SERVER_IMAGE_ROOT directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Python Function Packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the Keras MNIST Image Classification Data\n",
    "\n",
    "Use the MNIST data provided by Keras. For more information on the MNIST data, see https://keras.io/datasets/#mnist-database-of-handwritten-digits. Convenience functions provided by Keras load the data and assign labels to the training and test data.  There should be 60000 training images and 10000 test images.  Each image should be 28 pixels by 28 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training images = 60000\n",
      "Number of test images = 10000\n",
      "Image size = 28 x 28\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# convert class vectors to binary class matrices - this effectively gives a classification\n",
    "# label for each image\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(\"Number of training images = \" + str(x_train.shape[0]))\n",
    "print(\"Number of test images = \" + str(x_test.shape[0]))\n",
    "print(\"Image size = \" + str(x_train.shape[1]) + \" x \" + str(x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Test Images Before Loading into SAS CAS / Viya\n",
    "\n",
    "\n",
    "The test images for the example are stored in Python numpy arrays. There is not a direct way to convert a numpy array to a SAS CAS table, so the example first stores the test images in an intermediate PNG format. Afterwards, the example performs image processing actions and then loads the stored PNG images into a SAS CAS table.  Note that the action that loads images expects the following directory structure:\n",
    "\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/label1\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/label2\n",
    "<br>\n",
    "...\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/labelN\n",
    "<br>\n",
    "\n",
    "In this instance, CLIENT_IMAGE_ROOT specifies the name of the root image directory on the client, and \"label1\", \"label2\", ..., \"labelN\" \n",
    "represents the N image classes.  All the images that belong to image class \"label1\" should reside in the CLIENT_IMAGE_ROOT/label1 directory, all the images that belong to image class \"label2\" should reside in the CLIENT_IMAGE_ROOT/label2 directory, and so on.\n",
    "\n",
    "The MNIST image data contains 10 object classes. Each class is assigned a label \"0\", \"1\", ..., \"9\".  The example code assigns the test images to 10 separate directories as follows:\n",
    "\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/0\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/1\n",
    "<br>\n",
    "...\n",
    "<br>\n",
    "CLIENT_IMAGE_ROOT/9\n",
    "<br>\n",
    "\n",
    "Note: This example assumes that if the CLIENT_IMAGE_ROOT directory exists, then all image files have been unpacked and are ready for processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image directory exists, assuming image files prepared for loading into CAS table\n"
     ]
    }
   ],
   "source": [
    "# check if working directory exists\n",
    "if os.path.isdir(client_image_root):\n",
    "    print(\"Image directory exists, assuming image files prepared for loading into CAS table\")\n",
    "else:\n",
    "    os.mkdir(client_image_root)\n",
    "    \n",
    "    # create subdirectories for each image class\n",
    "    for ii in range(10):\n",
    "        new_path = os.path.join(client_image_root,str(ii))\n",
    "        if not os.path.isdir(new_path):\n",
    "            os.mkdir(new_path)\n",
    "\n",
    "    # distribute images to proper directories\n",
    "    im_index = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
    "    for ii in range(x_test.shape[0]):\n",
    "        im = Image.fromarray(x_test[ii,])\n",
    "        idx = np.where(y_test[ii])[0][0]\n",
    "        file_name = 'im'+str(idx)+'_file'+str(im_index[idx])+'.png'\n",
    "        new_path = os.path.join(client_image_root,str(idx))\n",
    "        im.save(os.path.join(new_path,file_name))\n",
    "        im_index[idx] = im_index[idx] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# If your client/server do not share a common file system, please copy the image files and subdirectories from CLIENT_IMAGE_ROOT to \n",
    "# SERVER_IMAGE_ROOT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The following code converts the image data to floating point and scales it such that all pixel values fall within the range 0.0 to 1.0.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scale the 60,000 train images and the 10,000 test images.\n",
    "x_train = x_train.reshape(60000, 28, 28, 1)\n",
    "x_test = x_test.reshape(10000, 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Keras LeNet Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the Architecture for a Keras LeNet \n",
    "# Image Classification Model\n",
    "\n",
    "# training parameters\n",
    "batch_size = 128\n",
    "epochs = 1\n",
    "\n",
    "# model architecture and activation functions\n",
    "model = Sequential()\n",
    "model.add(Conv2D(20, kernel_size=(5, 5), strides=(1, 1), activation='relu', input_shape=(28,28,1), padding=\"same\"))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Conv2D(50, kernel_size=(5, 5), strides=(1, 1), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# print a model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provide Trained LeNet Model Parameters\n",
    "\n",
    "After you define the Keras LeNet model architecture, you must either train the model from scratch, or you can supply the model with an archived set of trained model parameters in HDF5 format. In this instance we load the model with trained parameters as defined in the file CLIENT_IMAGE_ROOT/lenet.h5. \n",
    "\n",
    "If you want to train the model from scratch, set the value for the do_train parameter to True. To load pretrained model parameters saved in an HDF5 file, set the value for the do_train parameter to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.12472512652352452\n",
      "Test accuracy: 0.9601\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer=RMSprop(),metrics=['accuracy'])\n",
    "\n",
    "# Set the LeNet model do_train parameter to False\n",
    "# and supply the model with a pretrained parameter \n",
    "# file named \"lenet.h5\".\n",
    "\n",
    "do_train = False\n",
    "if do_train:\n",
    "    history = model.fit(x_train, y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1,\n",
    "    validation_data=(x_test, y_test))\n",
    "    \n",
    "    model.save(os.path.join(client_image_root,\"lenet.h5\"))\n",
    "else:    \n",
    "    # Load the previously trained parameter file \"lenet.h5\" in lieu\n",
    "    # of training the LeNet model from scratch.\n",
    "    model.load_weights(os.path.join(client_image_root,\"lenet.h5\"))\n",
    "\n",
    "# Now use the trained model to score the test Data.\n",
    "    \n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to the SAS CAS Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configure matplotlib utility to display output in \n",
    "# Jupyter notebook cell\n",
    "%matplotlib inline\n",
    "\n",
    "# SAS Scripting Wrapper for Analytic Transfer (SWAT)\n",
    "# is a module needed to connect to a CAS server.\n",
    "from swat import * \n",
    "\n",
    "# start SAS CAS session\n",
    "s = CAS(\"<CAS server IP address>\", <port number>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Convert the Keras Model to a SAS Viya Model\n",
    "\n",
    "Two operations take place when the from_keras_model() function is called. The first operation automatically translates the Keras model into a SAS Deep Learning model.  You can perform this process manually, but it is not recommended because it is error-prone and time-consuming.  \n",
    "\n",
    "The second operation rearranges and reformats the HDF5 parameter file that was generated by Keras.  Rearranging and reformatting the parameter file enables the SAS Deep Learning action set to correctly parse and read the trained parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: could not find layer conv2d_1_input, in model. Translated model may be inaccurate.\n",
      "NOTE: Added action set 'deeplearn'.\n",
      "NOTE: Model table is attached successfully!\n",
      "NOTE: Model is named to \"lenet\" according to the model name in the table.\n",
      "NOTE: the model weights has been stored in the following file:\n",
      "lenet_weights.kerasmodel.h5\n"
     ]
    }
   ],
   "source": [
    "from dlpy import Model\n",
    "# Convert the Keras model to a SAS Viya model\n",
    "# Convert Keras model parameters to a format \n",
    "# that can be read by SAS DLPy and the SAS \n",
    "# Deep Learning toolkit.\n",
    "model_name = 'lenet'\n",
    "model1 = Model.from_keras_model(conn=s, keras_model=model, output_model_table=model_name,\n",
    "                               include_weights=True, scale=1.0/255.0,\n",
    "                               input_weights_file=os.path.join(client_image_root,\"lenet.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy the Reformatted HDF5 File\n",
    "\n",
    "This is for convenience, in the event that your client and server share a common file system.  If there is no common file system, then you must perform a copy operation to transfer the HDF5 file from one file system to another.  Remember that deep learning HDF5 files can be quite large, so the data transfer could take a significant amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lenet_weights.kerasmodel.h5'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from shutil import copyfile\n",
    "copyfile('lenet_weights.kerasmodel.h5', os.path.join(client_image_root,\"lenet_weights.kerasmodel.h5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the SAS Viya Model with Trained Parameters\n",
    "\n",
    "Up to this point, the SAS Viya model contains parameters that were initialized according to the default settings supplied when the model was created in the preceding step. Now we will import the trained parameters from the Keras model and install them into the SAS Viya model. \n",
    "\n",
    "It is also a good idea at this time to apply labels to the output of the classification layer. The layers should be consistent with the labels that we will shortly apply to the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: Cloud Analytic Services made the uploaded file available as table NEW_LABEL_TABLE_PBN9HI in caslib CASUSER.\n",
      "NOTE: The table NEW_LABEL_TABLE_PBN9HI has been created in caslib CASUSER from binary data uploaded to Cloud Analytic Services.\n",
      "NOTE: no dataspec(s) provided - creating image classification model.\n",
      "NOTE: Model weights attached successfully!\n"
     ]
    }
   ],
   "source": [
    "model1.load_weights(path=server_image_root+\"/lenet_weights.kerasmodel.h5\",\n",
    "                    labels=True,\n",
    "                    label_file_name=os.path.join(os.getcwd(),\"mnist_labels.csv\"),\n",
    "                    label_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize the SAS Viya Model Architecture\n",
    "\n",
    "Please compare the SAS Viya model architecture and parameter count in this summary to the model architecture and parameter count from the Keras model above. The model layers and model layer definitions may differ somewhat between the Keras and SAS Viya models, but the total number of trained parameters in the two models should be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer Id</th>\n",
       "      <th>Layer</th>\n",
       "      <th>Type</th>\n",
       "      <th>Kernel Size</th>\n",
       "      <th>Stride</th>\n",
       "      <th>Activation</th>\n",
       "      <th>Output Size</th>\n",
       "      <th>Number of Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>conv2d_1_input</td>\n",
       "      <td>input</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>(28, 28, 1)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>conv2d_1</td>\n",
       "      <td>convo</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>1</td>\n",
       "      <td>Rectifier</td>\n",
       "      <td>(28, 28, 20)</td>\n",
       "      <td>(500, 20)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>max_pooling2d_1</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>Max</td>\n",
       "      <td>(14, 14, 20)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>conv2d_2</td>\n",
       "      <td>convo</td>\n",
       "      <td>(5, 5)</td>\n",
       "      <td>1</td>\n",
       "      <td>Rectifier</td>\n",
       "      <td>(14, 14, 50)</td>\n",
       "      <td>(25000, 50)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>max_pooling2d_2</td>\n",
       "      <td>pool</td>\n",
       "      <td>(2, 2)</td>\n",
       "      <td>2</td>\n",
       "      <td>Max</td>\n",
       "      <td>(7, 7, 50)</td>\n",
       "      <td>(0, 0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>dense_1</td>\n",
       "      <td>fc</td>\n",
       "      <td>(2450, 500)</td>\n",
       "      <td></td>\n",
       "      <td>Rectifier</td>\n",
       "      <td>500</td>\n",
       "      <td>(1225000, 500)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>dense_2</td>\n",
       "      <td>output</td>\n",
       "      <td>(500, 10)</td>\n",
       "      <td></td>\n",
       "      <td>Softmax</td>\n",
       "      <td>10</td>\n",
       "      <td>(5000, 10)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1256080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Layer Id            Layer    Type  Kernel Size Stride Activation  \\\n",
       "0        0   conv2d_1_input   input                           None   \n",
       "1        1         conv2d_1   convo       (5, 5)      1  Rectifier   \n",
       "2        2  max_pooling2d_1    pool       (2, 2)      2        Max   \n",
       "3        3         conv2d_2   convo       (5, 5)      1  Rectifier   \n",
       "4        4  max_pooling2d_2    pool       (2, 2)      2        Max   \n",
       "5        5          dense_1      fc  (2450, 500)         Rectifier   \n",
       "6        6          dense_2  output    (500, 10)           Softmax   \n",
       "7                                                                    \n",
       "\n",
       "    Output Size Number of Parameters  \n",
       "0   (28, 28, 1)               (0, 0)  \n",
       "1  (28, 28, 20)            (500, 20)  \n",
       "2  (14, 14, 20)               (0, 0)  \n",
       "3  (14, 14, 50)          (25000, 50)  \n",
       "4    (7, 7, 50)               (0, 0)  \n",
       "5           500       (1225000, 500)  \n",
       "6            10           (5000, 10)  \n",
       "7                            1256080  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model1.print_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the MNIST Image Classification Test Data\n",
    "\n",
    "You will need to provide a path to your environment's server path in order to load the MNIST test data images. This example uses a path placeholder called SERVER_IMAGE_ROOT. Your path will be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import SAS DLPy simple image processing functions\n",
    "from dlpy.images import ImageTable\n",
    "\n",
    "# load the MNIST image classification model test data images\n",
    "my_images = ImageTable.load_files(s, path=server_image_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Appearance of Test Data Images\n",
    "\n",
    "After loading the MNIST model test data images into the SAS Viya model in DLPy, display a matrix of 8 random images arranged in 4 columns. Verify that the test images resemble various hand-written Arabic numerals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA48AAAHHCAYAAAAf/W0nAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCmPAAAAFCmPAAAAFP0/eiTQI2g31YYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x170d7a21278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "my_images.show(nimages=8,ncol=4, randomize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score the Test Images with the Viya Model\n",
    "\n",
    "Now use the SAS Viya classification model to score the test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Descr         Value\n",
      "0  Number of Observations Read         10000\n",
      "1  Number of Observations Used         10000\n",
      "2  Misclassification Error (%)          3.99\n",
      "3                   Loss Error      0.124725\n"
     ]
    }
   ],
   "source": [
    "# score images\n",
    "viya_score = model1.predict(my_images, buffer_size=batch_size, n_threads=1)\n",
    "print(viya_score['ScoreInfo'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify the Results\n",
    "\n",
    "Compare the classification results generated by the Keras model and the imported SAS Viya model.\n",
    "These results should be identical or nearly so.  Note that the Keras model reports classification rate, while the SAS Viya model reports misclassification rate. To compare classification rates, calculate the classification rate of the SAS Viya model as follows:\n",
    "\n",
    "SAS Viya Model Classification Rate = (100 - SAS Viya Model Misclassifcation Rate).\n",
    "\n",
    "The code below calculates the classification rate in terms of the percent of images correctly classified.  The output shows that the original Keras image classification model and the imported SAS Viya image classification model deliver identical classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Viya classification rate = 96.01%\n",
      "Keras classification rate = 96.01%\n"
     ]
    }
   ],
   "source": [
    "print('Viya classification rate = ' + \"{:2.2f}\".format(100.0-float(viya_score['ScoreInfo']['Value'][2])) + '%')\n",
    "print('Keras classification rate = ' + \"{:2.2f}\".format(100.0*score[1]) + '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terminate the SAS Viya Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"cas-output-area\"></div>\n",
       "<p class=\"cas-results-performance\"><small><span class=\"cas-elapsed\">elapsed 0.000241s</span> &#183; <span class=\"cas-sys\">sys 0.000857s</span> &#183; <span class=\"cas-memory\">mem 0.194MB</span></small></p>"
      ],
      "text/plain": [
       "+ Elapsed: 0.000241s, sys: 0.000857s, mem: 0.194mb"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.endsession()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
